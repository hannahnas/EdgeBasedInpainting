project: Thesis
name: Skip Attention

parameters:
    model name: 'SkipAttentionGatedEncoder'
    model class: 'SkipAttentionModel'
    multiscale: False
    batch size: 4
    lr: 0.0001
    monitor: 'val_l1_depth_loss'
    epochs': 8